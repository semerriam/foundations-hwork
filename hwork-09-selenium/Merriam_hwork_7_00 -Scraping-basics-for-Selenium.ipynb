{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping basics for Selenium\n",
    "\n",
    "If you feel comfortable with scraping, you're free to skip this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports\n",
    "\n",
    "Import what you need to use Selenium, and start up a new Chrome to use for scraping. You might want to copy from the [Selenium snippets](http://jonathansoma.com/lede/foundations-2018/classes/selenium/selenium-snippets/) page.\n",
    "\n",
    "**You only need to do `driver = webdriver.Chrome(...)` once,** every time you do it you'll open a new Chrome instance. You'll only need to run it again if you close the window (or want another Chrome, for some reason)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the necessary imports\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST chromedriver version for 96.0.4664 google-chrome\n",
      "Driver [/Users/susanmerriam/.wdm/drivers/chromedriver/mac64/96.0.4664.45/chromedriver] found in cache\n",
      "/var/folders/8t/1rrw8b2x05595s5gystxsg3m0000gn/T/ipykernel_58437/4290991195.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Launch a new Chrome, install the appropriate ChromeDriver if necessary\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Scraping by class\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/by-class.html, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/by-class.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "titles = driver.find_elements(By.CLASS_NAME, \"title\")\n",
    "for title in titles:\n",
    "    print(title.text)\n",
    "\n",
    "subhead = driver.find_elements(By.CLASS_NAME, \"subhead\")\n",
    "for title in subhead:\n",
    "    print(title.text)\n",
    "    \n",
    "byline = driver.find_elements(By.CLASS_NAME, \"byline\")\n",
    "for title in byline:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scraping using tags\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/by-tag.html, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/by-tag.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "h1 = driver.find_elements(By.TAG_NAME, \"h1\")\n",
    "for title in h1:\n",
    "    print(title.text)\n",
    "\n",
    "h3 = driver.find_elements(By.TAG_NAME, \"h3\")\n",
    "for title in h3:\n",
    "    print(title.text)\n",
    "\n",
    "p = driver.find_elements(By.TAG_NAME, \"p\")\n",
    "for title in p:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Scraping using a single tag\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/by-list.html, printing out the title, subhead, and byline.\n",
    "\n",
    "> **This will be important for the next few:** if you scrape multiples, you have a list. Even though it's Seleninum, you can use things like `[0]`, `[1]`, `[-1]` etc just like you would for a normal list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/by-list.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "p2 = driver.find_elements(By.TAG_NAME, \"p\")\n",
    "print(p2[0].text)\n",
    "print(p2[1].text)\n",
    "print(p2[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets everything / all the p's\n",
    "# p2 = driver.find_elements(By.TAG_NAME, \"p\")\n",
    "# for title in p2:\n",
    "#     print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By.CLASS_NAME or By.ID or By.CSS_SELECTOR\n",
    "# resource: https://jonathansoma.com/lede/foundations-2018/classes/selenium/scraping-supplement/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Scraping a single table row\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/single-table-row.html, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/single-table-row.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "# Find all of the tds on the page\n",
    "cells = driver.find_elements(By.TAG_NAME, \"td\")\n",
    "# Print out the first one, the second one, the third one\n",
    "print(cells[0].text)\n",
    "print(cells[1].text)\n",
    "print(cells[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find all of the tds on the page\n",
    "# cells = driver.find_elements_by_tag_name('td')\n",
    "# # Print out the first one, the second one, the third one\n",
    "# print(\"The title is\", cells[0].text)\n",
    "# print(\"Subhead is\", cells[1].text)\n",
    "# print(\"Byline is\", cells[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Saving into a dictionary\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/single-table-row.html, saving the title, subhead, and byline into a single dictionary called `book`.\n",
    "\n",
    "> Don't use pandas for this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/single-table-row.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'How to Scrape Things', 'subhead': 'Some Supplemental Materials', 'byline': 'By Jonathan Soma'}\n"
     ]
    }
   ],
   "source": [
    "# Find all of the tds on the page\n",
    "cells2 = driver.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "# Start with an empty dictionary\n",
    "book = {}\n",
    "\n",
    "# Add the keys one by one\n",
    "book['title'] = cells2[0].text\n",
    "book['subhead'] = cells2[1].text\n",
    "book['byline'] = cells2[2].text\n",
    "\n",
    "# Print it out\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Scraping multiple table rows\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/multiple-table-rows.html, printing out each title, subhead, and byline.\n",
    "\n",
    "> You won't use pandas for this one, either!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/multiple-table-rows.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n",
      "How to Scrape Many Things\n",
      "But, Is It Even Possible?\n",
      "By Sonathan Joma\n",
      "The End of Scraping\n",
      "Let's All Use CSV Files\n",
      "By Amos Nathanos\n"
     ]
    }
   ],
   "source": [
    "rows = driver.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "for row in rows:\n",
    "  # Find all of the tds inside of THAT ONE ROW\n",
    "  cells3 = row.find_elements(By.TAG_NAME, \"td\")\n",
    "  # Print out the first one, the second one, the third one\n",
    "  print(cells3[0].text)\n",
    "  # gives second td (column 2) in each row\n",
    "  print(cells3[1].text)\n",
    "  # gives third td (column 3) in each row\n",
    "  print(cells3[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Scraping an actual table\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/the-actual-table.html, creating a list of dictionaries.\n",
    "\n",
    "> Don't use pandas here, either!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/the-actual-table.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows2 = driver.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# for row in rows2:\n",
    "#   # Find all of the tds inside of THAT ONE ROW\n",
    "#   cells4 = row.find_elements(By.TAG_NAME, \"td\")\n",
    "#   # Print out the first one, the second one, the third one\n",
    "#   print(cells4[0].text)\n",
    "#   # gives second td (column 2) in each row\n",
    "#   print(cells4[1].text)\n",
    "#   # gives third td (column 3) in each row\n",
    "#   print(cells4[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n",
      "How to Scrape Many Things\n",
      "But, Is It Even Possible?\n",
      "By Sonathan Joma\n",
      "The End of Scraping\n",
      "Let's All Use CSV Files\n",
      "By Amos Nathanos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/1rrw8b2x05595s5gystxsg3m0000gn/T/ipykernel_58437/2303767929.py:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  table = driver.find_element_by_id('booklist')\n"
     ]
    }
   ],
   "source": [
    "# for multiple tables on the page, grab table by id\n",
    "table = driver.find_element_by_id('booklist')\n",
    "rows3 = table.find_elements_by_tag_name('tr')\n",
    "\n",
    "for row in rows3:\n",
    "  # Find all of the tds inside of THAT ONE ROW\n",
    "  cells5 = row.find_elements_by_tag_name('td')\n",
    "  # Print out the first one, the second one, the third one\n",
    "  print(cells5[0].text)\n",
    "  print(cells5[1].text)\n",
    "  print(cells5[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'How to Scrape Things', 'subhead': 'Some Supplemental Materials', 'byline': 'By Jonathan Soma'}\n",
      "{'title': 'How to Scrape Many Things', 'subhead': 'But, Is It Even Possible?', 'byline': 'By Sonathan Joma'}\n",
      "{'title': 'The End of Scraping', 'subhead': \"Let's All Use CSV Files\", 'byline': 'By Amos Nathanos'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/1rrw8b2x05595s5gystxsg3m0000gn/T/ipykernel_58437/163036253.py:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  table = driver.find_element_by_id('booklist')\n",
      "/Users/susanmerriam/.pyenv/versions/3.10.0/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:359: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    }
   ],
   "source": [
    "# # for multiple tables on the page, grab table by id\n",
    "# table = driver.find_element_by_id('booklist')\n",
    "# rows3 = table.find_elements_by_tag_name('tr')\n",
    "\n",
    "# for row in rows3:\n",
    "#   # Find all of the tds inside of THAT ONE ROW\n",
    "#     cells5 = row.find_elements_by_tag_name('td')\n",
    "    \n",
    "#     # Start with an empty dictionary\n",
    "#     book2 = {}\n",
    "  \n",
    "#     # Print out the first one, the second one, the third one\n",
    "#     book2['title'] = cells5[0].text\n",
    "#     book2['subhead'] = cells5[1].text\n",
    "#     book2['byline'] = cells5[2].text\n",
    "\n",
    "#     # Print it out\n",
    "#     print(book2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'How to Scrape Things', 'subhead': 'Some Supplemental Materials', 'byline': 'By Jonathan Soma'}, {'title': 'How to Scrape Many Things', 'subhead': 'But, Is It Even Possible?', 'byline': 'By Sonathan Joma'}, {'title': 'The End of Scraping', 'subhead': \"Let's All Use CSV Files\", 'byline': 'By Amos Nathanos'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/1rrw8b2x05595s5gystxsg3m0000gn/T/ipykernel_58437/1030727018.py:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  table = driver.find_element_by_id('booklist')\n",
      "/Users/susanmerriam/.pyenv/versions/3.10.0/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:359: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    }
   ],
   "source": [
    "# for multiple tables on the page, grab table by id\n",
    "table = driver.find_element_by_id('booklist')\n",
    "rows4 = table.find_elements_by_tag_name('tr')\n",
    "\n",
    "books = []\n",
    "for row in rows4:\n",
    "  # Find all of the tds inside of THAT ONE ROW\n",
    "    cells6 = row.find_elements_by_tag_name('td')\n",
    "    \n",
    "    # Start with an empty dictionary\n",
    "    book3 = {}\n",
    "  \n",
    "    # Print out the first one, the second one, the third one\n",
    "    book3['title'] = cells6[0].text\n",
    "    book3['subhead'] = cells6[1].text\n",
    "    book3['byline'] = cells6[2].text\n",
    "    \n",
    "    # append list with elements of book3 dictionay    \n",
    "    books.append(book3)\n",
    "\n",
    "# Print it out\n",
    "print(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Scraping multiple table rows into a list of dictionaries\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/the-actual-table.html, creating a pandas DataFrame.\n",
    "\n",
    "> There are two ways to do this one! One uses just pandas, the other one uses the result from Part 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subhead</th>\n",
       "      <th>byline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Scrape Things</td>\n",
       "      <td>Some Supplemental Materials</td>\n",
       "      <td>By Jonathan Soma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Scrape Many Things</td>\n",
       "      <td>But, Is It Even Possible?</td>\n",
       "      <td>By Sonathan Joma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The End of Scraping</td>\n",
       "      <td>Let's All Use CSV Files</td>\n",
       "      <td>By Amos Nathanos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title                      subhead            byline\n",
       "0       How to Scrape Things  Some Supplemental Materials  By Jonathan Soma\n",
       "1  How to Scrape Many Things    But, Is It Even Possible?  By Sonathan Joma\n",
       "2        The End of Scraping      Let's All Use CSV Files  By Amos Nathanos"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe from list of dictionaries. \n",
    "# keys become columns, values rows\n",
    "# index gets added in the conversion\n",
    "\n",
    "df = pd.DataFrame(books)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Scraping into a file\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/the-actual-table.html and save it as `output.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index=False to prevent the 'extra' number column\n",
    "df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
